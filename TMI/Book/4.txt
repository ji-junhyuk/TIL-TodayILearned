제목 : HelloCoding 그림으로 개념을 이해하는 알고리즘

Chapter 1. 알고리즘의 소개
이진 ㄴ탐색은 단순 탐색보다 아주 빠르다.
O(log n)은 O(n)보다 빠르다. 리스트의 원소 개수가 증가하면 상대적으로 더 빨라진다.
알고리즘의 속도는 시간으로 측정하지 않습니다.
알고리즘의 시간은 어떻게 증가하는가로 측정합니다
알고리즘의 시간은 빅오 표기법으로 나타냅니다.

Chapter 2. 선택 정렬
=> 컴퓨터 메모리는 거대한 서랍장과 같다
=> 여러 개의 항목을 저장하고 싶을 때는 배열이나 리스트를 사용해라
-> 배열을 쓰면 모든 항목은 이웃하는 위치에 저장된다.
=> 리스트를 쓰면 모든 항목이 흩어지지만 각 항목은 다음 항목의 주소를 저장하고 있다.
=> 배열은 읽기가 빠르다
=> 연결 리스트는 삽입과 삭제가 빠르다
=> 배열의 모든 원소는 같은 자료형이어야 한다.

빅오 표기법에서 1/2같은 상수항은 무시한다.


Chapter 3. 재귀
=>재귀는 함수가 스스로 호출하는 것
=> 모든 재귀 함수는 기본 단계와 재귀 단계라는 두 부분으로 나뉘어져 있습니다.
=> 스텍에는 푸시와 팝 이라는 두 가지 연산이 있습니다. (삽입과 제거)
=> 모든 함수 호출은 호출 스택을 ㅅ사용합니다.
=> 호출 스택은 너무 ㄱ커져서 메모리르 ㄹ엄처안게 소비할 수도 있습니다.

<꼬리 재귀>



Chapter 4. 퀵 정렬
유클리드 호제법 (직사각형 논에 크기는 똑같지만 최대한 큰 정사각형을 나누기, 작은 직사각형만 생각하면 된다)
반복문과 재귀적 표현(함수형 프로그래밍, functional programming 중 하스켈에는 반복문이 없다)

빅오 표기법
이진탐색O(log n) 
단순탐색O(n)
퀵 정렬O(n log n)
선택 정렬O(n^2)
외판원 문제(n!)


분할 정복은 더 작은 조각으로 나누어 풉니다. 만약 리스트에 분할 정복을 적용한다면 기본 단계는 원소가 없는 빈 배열이거나 하나의 원소만 가진 배열이 됩니다.
퀵 정렬을 구현하려면 기준 원소를 무작위로 선택합니다. 퀵 정렬의 평균적인 실행시간은 O(n log n)입니다.
빅오 표기법에서 가끔씩 상수가 중요해질 때도 있습니다. 퀵 정렬이 병합 정렬보다 빠른 이유도 상수 입니다.
단순 탐색과 이진 탐색을 비교할 때는 상수항이 전혀 문제가 되지 않습니다. ㅇ리스트기 길어지면 차이가 확실하게 나기 때문이죠.

Chapter 5. 해시 테이블 
여러분이 스스로 해시 테이블을 구현할 일은 거의 없다. 프로그래밍 언어는 해시 테이블을 제공하기 때문이다. 

해시 테이블은 속도가 빠르고 자료를 여럭 가지로 모형화할 수 있기에 아주 강력한 자료 구조 입니다. 항상 해시 테이블을 사용하고 있는 나 자신을 발견하게 될 것이다.

=>해시 테이블은 해시 함수와 배열을 결합해서 만든다.
=>충돌은 나쁘다. 충돌을 줄이는 해시 함ㅅ후가 있어야 한다.
=>해시 테이블은 정말 빠른 탐색, 삽입, 삭제 속도를 가진다.
=>해시 테이블은 어떤 항목과 다른 항목의 관계를 모형화 하는데 좋다.
=>사용률이 0.7보다 커지면 해시 테이블을 리사이징해야 한다.
=>서버에 작업을 시키지 않고 해시 테이블은 (웹 서버 등) 데이터를 캐싱하는 데도 사용된다.
=>해시 테이블은 중복을 잡아내는 데도 뛰어나다.

해시함수 : 문자열을 받아서 숫자를 반환하는 함수이다.
일관성이 있어야 한다.
다른 단어가 들어가면 다른 숫자가 나와야 한다.
가장 좋은 경우는 서로 다른 단어에 대해 모두 서로 다른 숫자가 나와야 한다.
해시 함수는 정말 중요하다. 해시 ㅎ함수는 키를 해시 테이블 전체에 고르게 할당해야 한다
연결 리스트가 길어지면 해시 테이블의 속도가 느려진다. 하지만 좋은 해시 함수라면 그렇게 길어지지 않는다.

해시테이블(평균)(최악)(배열)(연결리스트)
탐색 O(1)/O(n)/O(1)/O(n) 
삽입 O(1)/O(n)/O(n)/O(1)
삭제 O(1)/O(n)/O(n)/O(1)

Chapter 6. 너비 우선 탐색
새로운 추상 자료구조인 그래프(graph)사용하여 네트워크 모형화
너비 우선 탐색(breadth-first search)를 이요하여 "X로 가는 최단 경로는 무엇일까"와 같은 문제에 답하는 알고리즘입니다.
: 체커게임에서 가장 적은 수로 승리할 수 있는 방버을 계산하느 ㄴ인공지능
: 맞춤법 검사기
: 내 네트워크에서 내과의사 찾기
너비 우선 탐색은 다음과 같은 두 가지 종류의 질문에 대답하는 데 도움된다.
1. 정점 A에서 정점 B로 가는 경로가 존재하는가?
2. 정점 A에서 정점 B로 가는 최단 경로는 무엇인가?

큐(대기열) 삽입과 제거, 선입선출
=> 너비 우선 탐색은 A에서 B로 가는 경로가 있는지 알려준다.
=> 만약 경로가 존재한다면 최단 경로를 찾아준다.
=> 문제를 그래프로 모형화하기
=> 방향 그래프는 화살표, 이는 관계를 나타냄(jun -> anna 준이 anna에게 돈을 빚지고 있는 상태입니다)
=> 무방향 그래프는 화살표가 없고, 둘 간의 상호 관계를 나타냅니다.(rose - roy는 rose와 roy가 서로 데이트 했다는 뜻이다.)
=> 큐는 선입선출, 스택은 후입선출
=> 탐색 목록에 추가된 순서대로 사람을 확인해야 합니다. 그래서 탐색 목록은 큐가 되어야 합니다. 그렇지 않으면 최단 경로를 구할 수 없습니다.
=> 누군가를 확인한 다음 두번 다시 확인하지 않도록 합니다. 그렇지 않으면 무한 반복에 빠질 수 있습니다.

방향 그래프와 무방향 그래프(undirected graph)
각 정점(node)간의 의존성을 표현하는 정렬 알고리즘의 일종인 위상 정렬(topological sort)


Chapter 7. 다익스트라 알고리즘
그래프의 간선에 가중치를 준 가중 그래프(weighted graph) : 간선에 숫자를 가중치라고 하고 가중치를 가지는 그래프를 가중 그래프라고 한다. 가중치가 없는 경우 균일 그래프라고 한다.(unweighted graph)
가중 그래프에서 X까지의 최단 경로를 구하는 다익스트라 알고리즘(Dijkstra's algorithm)

너비 우선 탐색(가장 짧은 길)이 있다. 하지만 구간을 지날 때마다 시간을 측정해보면 더 빠른 구간이 있을 수도 있다.

다익스트라 알고리즘
1. 가장 "가격"이 "싼" 정점을 찾는다. 가장 가격이 싼 정점이란 도달하는 데 시간이 가장 적게 걸리는 정점이다.
2. 이 정점의 이웃 정점들의 가격을 조사한다. 
3. 그래프 상 모든 정점에 대해 이러한 일을 반복한다.
4. 최종 경로를 계산한다.

음의 가중치를 가진 간선이 있으면 다익스트라 알고리즘을 사용할 수 없다. 벨만-포드 알고리즘(Bellman-Ford algorithm)을 사용해야 한다.
=> 너비 우선 탐색은 가중치가 없는 균일 그래프에서 최단 경로를 계산하는 데 사용됩니다.
=> 다익스트라 알고리즘은 가중 그래프에서 최단 거리를 계산하는 데 사용됩니다.
=> 다익스트라 알고리즘은 모든 가중치가 양수일 때만 정상적으로 작동합니다.
-> 가중치가 음수이면 벨만-포드 알고리즘을 사용합니다. 

Chapter 8. 탐욕 알고리즘(greedy algorithm)
탐욕 알고리즘은 의심스러울만큼 간단하다. 하지만 간단한 것이 장점이다. 각각의 단계에서 최적의 수를 찾아내면 된다. 기술적 용어로 말하자면 국소 최적해(locally optimal solution)을 찾음으로써 최정적으로는 전역 최적해(globally optimal solution)을 구하게 된다. 항상 성공하는 것은 아니지만 간단해서 구현하기 좋다.
그냥 "정답에 상당히 가까운" 답이기만 해도 충분할 때 사용한다. 

근사 알고리즘의 성능은 다음 두가지로 판단한다.
-얼마나 빠른가
-최적해에 얼마나 가까운가

NP-완전 문제
집합 커버링 문제(set-covering problem)을 풀기 위해서는 가능한 모든 집합을 계산해야 한다.
근사화 : 일단 아무 도시나 고른다. 그리고 아직 방문하지 않은 가장 가까운 도시를 다음 방문지로 선택한다.

어떤 문제가 NP-완전 문제인가?
1. 항목이 적을 때는 알고리즘이 빠른데, 늘어나면서 갑자기 느려진다
2. "X의 모든 조합"이라고 하면 보통 NP-완전 문제이다.
3. 더 작은 하위 문제로 변환할 수 없어서 X의 가능한 모든 버전을 계산해야 한다면 아마도
4. 문제가 수열을 포함하고 풀기가 어려우면
5. 만약 문제에 집합이 있고 풀기가 어려우면
6. 문제를 집합 커버링 문제나 외판원 문제로 재정의 할 수 있다면 명백하다.

탐욕 알고리즘
: 전역 최적화를 목표로 하지만, 국소 최적화를 한다
: NP 완전 문제는 빠른 해답이 알려지지 않았다.
: 만약 NP 완전 문제가 주어지면 근사 알고리즘을 쓰는 것이 최선이다.
: 탐욕 알고리즘은 작성하기도 쉽고 빠르기에 좋은 근사 알고리즘이 될 수 있다.
 

Chapter 9. 동적 프로그래밍(Dynamic programming)
어려운 문제를 여러 개의 하위 문제로 쪼개고, 이 하위 문제들을 먼저 해결하는 방법을 말한다. 어떤 제한 조건이 주어졌을 때 무언가를 최적화 하는 경우에 유용하다. 단 하위 문제가 서로 의존하지 않는 경우멘 사용 가능하다.

파인만 알고리즘(농담)
1. 문제를 작성한다
2. 열심히 생각한다
3. 답을 작성한다 

동적 프로그래밍을 풀 때는 격자를 사용한다.
격자의 각 칸에는 최적화하려는 값을 쓴다.
격자의 각 칸은 하위 문제를 뜻한다. 원래의 문제를 어떻게 하위 문제로 나눌 수 있을지 생각한다.
해답을 계산해주는 쉬운 계산 같은 것은 없다.

Chapter 10. KNN 알고리즘 (K-nearest neighbors algorithm)
오렌지와 자몽을 분류할 때 그래프 상에서 주변을 살펴 보는 것이다. 이웃 중에 오렌지가 많다면 오렌지로 분류된다. 

추천 시스템(넷플릭스)
= 고객을 그래프에 퓨ㅛ현할 수 있다면 두 고객 사이의 거리를 측정할 수 있다.
1. 특징 추출
2. 선호도 추출
=> 여러분들이 더 많은 영화를 평가할수록 넷플릭스는 여러분과 다른 고객과의 유사도를 더 정확하게 평가할 수 있습니다.

희귀분석 : 내가 이 영화에 대해 어떻게 평점을 줄지 예측하고 싶다면?
1. 분류 = 그룹으로 나누기
2. 회귀 = (숫자로 된) 반응을 예측하기

Tip 코사인 유사도 : 지금 까지 두 고객 사이의 거리를 비교할 때 거리 공식을 사용했다. 하지만 실무에서 더 흔히 사용되는 것은 코사인 유사도 이다. 두 고객은 아주 비슷하지만 평점을 주는 데 인색한 경우가 있다. 거리 공식을 사용했을 경우 이 둘은 이웃이 되지 않을 수 있기 때문이다. 코사인 유사도는 두 벡터의 거리를 측정하는 것이 아니라 두 벡터 사이의 각도를 측정합니다.

좋은 특징 고르기
1. 추천하고자 ㅎ하는 영화와 직접 관련이 있는 특징
2. 편향 되지 않은(예를 들어 코미디 영화에 평점만 있거나 액션 영화에 대한 평점만 있는 경우) 특징

머신 러닝(machine learning) : 여러분의 컴퓨텅를 더 영리하게 만드는 모든 것을 말한다.
광학적 문자 인식(OCR, optical Character Recognition) : 구글은 OCR을 이용하여 책을 디지털화 하였다.
KNN의 경우
1. 여러 가지 숫자 그림을 살펴보고 이 그림들의 특징을 뽑아낸다.
2. 새로운 그림이 주어지면 그 그림의 특징을 뽀방서 가장 가까운 것들과 살펴본다.
보통 OCR 알고리즘은 직선, 점, 곡선 등을 찾아낸다. 그런 다음 새로운 글자가 나타나면 그 글자에서 똑같은 특징을 뽑아낸다. 훨씬 복잡한 과정이 있겠지만 KNN과 같은 간단한 아이디어에 기반하고 있다는 점을 아는 것이 중요하다. 이를 음성 인식이나 얼굴 인식에도 사용할 수 있다.

특징을 추출하면서 모든 데이터를 살펴 보는 것을 트레이닝(training)이라고 한다.

스팸 필터 만들기 / 주식 시장 예측하기
KNN은 K개의 가장 가까운 이웃 데이터를 이욯아ㅕ 분류와 회귀 분석을 할 수 있다.
분류 = 그룹으로 나누는 작업
회귀 = 숫자로 된 반응을 예측
특징 추출은 (과일이나 고객과 같은) 항복을 비교 가능한 몇 개의 숫자로 만드는 일
좋은 특징을 고르는 것은 성공적인 KNN 알고리즘을 만드는 데 가장 중요한 것



Chapter 11. 더 공부해야 할 것 
트리 
페이스북 로그인 시 거대한 배열에서 지금 로그인한 사용자의 이름이 있는지를 찾습니다. 이때 가장 빠른 방법은 이진 탐색을 사용하는 것입니다. 하지만 문제가 있습니다. 사용자가 추가되면 배열을 다시 정렬해야 합니다. 이진 탐색은 정렬된 배열에만 사용할 수 있기 때문입니다. 사용자 이름을 올바른 위치에 바로 넣을 수 있다면 다시 정렬할 필요가 없다. 그래서 이진 탐색 트리(binary search tree)라는 자료 구조가 만들어지게 되었다. 

이진 탐색 트리에서 항목을 찾으려면 평균 O(log n) 시간이 걸리고, 최악의 경우 O(n) 시간이 걸립니다. 정렬된 배열에서는 최악의 경우에도 O(log n)시간이 걸립니다. 결과적으로 정렬된 배열이 더 낫긴 하지만 이진 탐색 트리는 항목을 삽입하거나 삭제할 때도 평균적으로 ㅎ ㅝㄹ씬 빠릅니다.
배열 = 탐색/삽입/삭제 O(log n)/O(n)/O(n)
이진 탐색 트리 = 탐색/삽입/삭제 O(log n)/O(log n)/O(log n)

이진 탐색 트리의 단점
하나의 임의 접근(random access)을 할 수 없다는 것입니다. "이 트리의 5번쨰 원소를 주세요"라고 말할 수 없습니다. 또 평균적인 성능이 트리가 얼마나 균형 잡혀 있는가에 따릅니다. 스스로 균형을 맞추는 특별한 이진 탐색 트리인 레드-블랙트리(red-black tree)라는 것도 있습니다. 데이터베이스나 고급 자료구조에 관심이 있다면 다음과 같은 것들을 공부해보세요. 
1. B-트리 (B-trees)
2. 레드-블랙 트리(red-black trees)
3. 힙(heap)
4. 스플레이 트리(splay trees)

역 인덱스
검색 엔진은 어떻게 작동하는가?
해시 테이블 키는 단어이고, 값은 그 단어가 어떤 웹페이지에 있는지를 나타냅니다. 사용자가 "안녕"이라는 단어를 검색할 때 웹페이지 A와 C를 보여주면 됩니다. 해시 테이블은 참 유용한 자료 구조입니다. 이런 자료구조를 역 인덱스(inverted indx)라고 합니다. 검색에 관심이 있다면 역 인덱스부터 공부하면 됩니다.


퓨리 변환(fourier transform)
아주 뛰어나고 세련되고 엄청나게 많은 응용 분야를 가지는 희귀한 알고리즘입니다. "퓨리에 변환을 이용하면 스무디가 무슨 성분으로 구성되어 있는지 알아내는 것처럼 ㅎ하나의 노래를 여러 개의 개별적인 주파수들로 분리할 수 있다"
이 단순한 개념은 엄청나게 많은 분야에 사용될 수 있습니다. 듣고 싶은 주파수만 듣거나 중저음 영역만 확대하고 고음 부분을 가리거나 할 수 있다. 음악 압축도 가능하다.지진이 발생하는 것을 예측하고 DNA를 분석하는 데도 역시 퓨리 변환을 사용합니다. 
=>Shazam 앱을 만들 때도 사용된다.


병렬알고리즘 : 엄청 많은 데이터를 다루는 방법
옛날에는 알고리즘을 더 빠르게 동작하도록 하려면 몇 달 기다리면 됐습니다. 컴퓨터가 더 빨라지니까요. 최근에는 여러 개의 코어가 탑재되었습니다. 병렬 알고리즘은 설계하기가 어렵습니다. 속도 향상이 선형적이지도 않습니다. 한 개의 코어가 아니라 두 개의 코어에서 알고리즘을 돌린다고 하더라도 마법처럼 두 배로 빨라지지 않습니다. 다음 이유가 있습니다.
1. 병렬화를 관리하는 데 들어가는 부담 (배열을 정렬한다고 할 떄 합치는 데도 시간이 걸립니다)
2. 로드 밸런싱(작업을 나누더라도 A코어는 쉬운 일, B코어는 어려운 일을 하여 B코어 혼자 열심히 일 할수도 있습니다. 일을 균등하게 배분하려면 어떻게 해야 할까요?)


맵리듀스 
인기 있는 병렬 알고리즘 중에 분산 알고리즘(distributed algorithm)이 있습니다. 맵리듀스 알고리즘은 그 중에 하나 입니다. 많은 작업을 하면서 실행 시간을 단축시키고 싶을 때 유용하다. 맵 함수와 리듀스 함수라는 두 개의 간단한 개념을 이용하여 만들어졌습니다.

멥 함수
배열을 입력 받아서 모든 원소에 같은 함수를 적용합니다. 만약 100개의 컴퓨터가 있다면 맵 함수는 이 작업을 모든 컴퓨터에 골고루 배분합니다. 작업이 훨씬 발라지겠죠. 이것이 맵리듀스에서 맵 합수의 개념입니다.

리듀스 함수 
리스트 전체의 원소를 하나의 원소로 축소 합니다. 맵 함수에서는 하나의 배열에서 같은 크기의 다른 배열을 얻었습니다. 하지만 리듀스에서는 이 배열을 하나의 원소로 변형합니다. 맵리듀스는 이 두가지의 간단한 개념을 이용해 여러 대의 컴퓨터가 분산되어 있는 데이터에 대한 질의를 수행합니다. 수십 억 개의 데이터가 있더라도 일반 데이터 베이스에서 몇 시간이 걸리는 작업을 몇 분만에 수행할 수 있습니다.


블룸 필터와 하이퍼로그로그
웹 서비스를 운영한다고 가정하자
1. 오늘 올라온 이 링크가 예전에 올라왔던 것인지 확인하고 싶은 경우
2. 구글이 웹 페이즈를 크롤링할 때 전에 크롤링 했던 것인지 알고 싶은 경우
3. 비틀리와 같이 URL을 단축해주는 사이트도 마찬가지, 사용자가 악성 코드가 있는 웹사이트로 가지 않도록 악성 코드 목록 확인해야 하는 경우
=> 확인해야 할 집합이 굉장히 크다.
해시테이블을 사용하면 해당 작업을 빨리 할 수 있다. 단 해시 테이블이 굉장히 크다는 단점이 있다.

블룸 필터 : 확률론적인 자료 구조
거의 대부분 옳은 답을 주긴 하지만, 항상 그렇지는 않습니다. 
=> 블룸 필터는 틀린 답을 맞다고 할 수 있다. 구글 서비스의 경우 "이미 크롤링 한 사이트 입니다"라고 해도 사실 크롤링하지 않았던 사이트일 수 있다.
=> 하지만 맞는 답을 틀리다고 하지는 않는다. "이 사이트는 크롤링하지 않았습니다"라는 답이 나오면 진짜 크롤링한 적이 없다는 뜻이다.
=> 이 사이트는 악성 코드가 있을 수도 있습니다. 그러니까 주의하세요.

하이퍼 로그로그 : 집합에 있는 똑같은 원소의 개수를 대략적으로 셀 수 있다. 정확한 값을 주지는 않지만 근사한 값을 주기 위해 필요한 메모리의 아주 일부분만 사용한다.


SHA 알고리즘
해시 함수가 좋은 분포 특성을 가져야 합니다. 해시 함수에 문자열을 넣으면 그 문자열을 저장할 위치를 알려줍니다.
SHA(보안 해시 알고리즘)Secure Hash Algorithm 함수도 해시 함수의 일종입니다. Google 서비스는 여러분의 패스워드 자체를 저장해 놓지 않습니다. 패스워드에 대한 SHA 해시값만 저장해 놓는 것이죠. 여러분이 패스워드를 입력하면 구글에서는 그 문자열에 대한 해시값을 계산하여 데이터베이스에 저장해 놓았던 패스워드의 해시값과 비교합니다.  그러니까 구글은 해시값을 비교할 뿐이지 패스워드 자체를 저장하는 것은 아닙니다. SHA는 이렇게 패스워드를 해시하는 데 자주 쓰입니다. SHA는 단방향 해시입니다. 문자열에서 해시값을 얻을 ㅅ수 는 있지만, 해시값에서 문자열을 알 수는 없습니다.


지역 민감 해싱
SHA : 지역 민감적이지 않다는 점. 두 개의 입력 문자열이 비슷하면 출력되는 해시값도 비슷해진다는 뜻이다.
이는 해커가 패스워드를 추측할 떄 패스워드와 어느 정도 비슷해졌는지 알 수 없기 때문에 좋은 특성이다. 하지만 어떨 때는 지역 민감 해시(locality-sensitive hash)가 필요한 경우도 있다. 이 경우 Simhash를 사용한다. 문자열이 조금 바뀌었을 때 해시값도 조금 바뀝니다. 
=> 구글은 크롤링할 웹 페이지가 중복되었는지 판단합니다.
=> 선생님은 학생이 작문 숙제를 인터넷에서 베꼈는지 알 수 있습니다.
=> Scribd 서비스는 사용자가 문서나 책을 업로드해서 다른 사람들과 공유하도록 합니다. 하지만 저작권이 있는 애요은 업로드하지 못하도록 합니다.
이처럼 비슷한 항목을 찾아낼 때 아주 유용하다.


디피-헬만 알고리즘(Diffie-Helman algorithm)
다음과 같은 두 가지 문제를 해결할 수 있었습니다.
1. 양쪽 모두 암호 해독 규칙을 가질 필요가 없다. 그러면 만나서 암호 해독 규칙을 공유할 필요도 없기 때문이다.
2. 암호화된 메시지는 해독하기 어려워야 합니다.
두개의 키를 가진다. 하나는 공개 키(public key)이고 다른 하나는 개인 키(private)입니다. 공개 키는 말 그대로 공개됩니다. 감출 필요가 없습니다. 누군가가 당신에게 메시지를 보내고 싶을 떄는 이 공개 키를 써서 암호화를 합니다. 다만 암호화된 메시지를 해독하기 위해서는 개인 키가 있어야 합니다.
디피-헬만 알고리즘은 후속 알고리즘인 RSA와 함께 현재도 많이 사용되고 있습니다.


선형 프로그래밍(linear programming)
그래프 알고리즘을 선형 프로그래밍 대신 사용할 수도 있습니다. 그래프 문제는 선형 프로그래밍의 특수한 경우에 지나지 않습니다. 선형 프로그래밍에서는 심플렉스 알고리즘이란 것을 사용합니다.(Simplex algorithm)
